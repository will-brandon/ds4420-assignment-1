{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98645648-2d3e-4e74-b6ca-2f71903f0ef1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d983657a-6616-4671-80b4-e8dd95c3050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional, Any, Tuple, List\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d15c5-21b6-4bb5-beeb-053ab71f65d7",
   "metadata": {},
   "source": [
    "## Reading Datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9eb5734-06a1-44c4-b71c-ccb525e95205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(filename, sep=',', encoding='latin-1')\n",
    "\n",
    "train_and_val_data = read_csv('data/ds4420_kaggle_train_data.csv')\n",
    "test_data = read_csv('data/ds4420_kaggle_test_data.csv')\n",
    "\n",
    "def split_label(data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    return data.drop('Label', axis=1), data['Label']\n",
    "\n",
    "X_train_and_val, y_train_and_val = split_label(train_and_val_data)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_and_val,\n",
    "                                                  y_train_and_val,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=1)\n",
    "\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eff251-788e-4728-ba1c-896ac5ea7beb",
   "metadata": {},
   "source": [
    "## Custom Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b6fe854-7992-415c-927d-946e2fd05213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdClassifier(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    model: BaseEstimator\n",
    "    threshold: int\n",
    "\n",
    "    def __init__(self, model: BaseEstimator, threshold: int=0.5) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "        self.model = model\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> ThresholdClassifier:\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: pd.Series) -> pd.DataFrame:\n",
    "        return self.model.predict_proba(X)[:,1] > self.threshold\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "\n",
    "    def __clean_text(self, text: str) -> str:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> TextCleaner:\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(self.__clean_text)\n",
    "        return feature\n",
    "\n",
    "class InteractFeaturesTransformer(FunctionTransformer):\n",
    "    \"\"\"\n",
    "    Multiplies two features together to yield a new feature.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        FunctionTransformer.__init__(self, self.__interact_features, validate=True)\n",
    "\n",
    "    def __interact_features(self, X: pd.DataFrame) -> pd.Series:\n",
    "        return X[:, 0:1] * X[:, 1:2]\n",
    "\n",
    "class LengthFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts a text feature into its length.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "    \n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> LengthFeatureExtractor:\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(lambda text: len(text))\n",
    "        return feature.values.reshape(-1, 1)\n",
    "\n",
    "class CapsBinaryFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts a text feature into a binary feature where 1 denotes that at least one word in the text\n",
    "    is completely capitalized, which is assumed to be yelling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "        \n",
    "    def __text_contains_caps_binary(self, text: str) -> int:\n",
    "        return int(any(word.isupper() for word in text.split(' ')))\n",
    "    \n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> CapsBinaryFeatureExtractor:\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(self.__text_contains_caps_binary)\n",
    "        return feature.values.reshape(-1, 1)\n",
    "\n",
    "class CapsCountFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts a text feature into a numeric feature count of the number of words in the text that are\n",
    "    completely capitalized, which is assumed to be yelling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "    \n",
    "    def __text_caps_count(self, text: str) -> int:\n",
    "        return int(sum(1 for word in text.split(' ') if word.isupper()))\n",
    "    \n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> CapsCountFeatureExtractor:\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(self.__text_caps_count)\n",
    "        return feature.values.reshape(-1, 1)\n",
    "\n",
    "class CharBinaryFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts a text feature into binary feature where 1 indicates the text containst at least one of\n",
    "    the given character.\n",
    "    \"\"\"\n",
    "\n",
    "    char: str\n",
    "    \n",
    "    def __init__(self, char: str) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "\n",
    "        if len(char) != 1:\n",
    "            raise ValueError('Character must be a string of length 1.')\n",
    "        \n",
    "        self.char = char\n",
    "    \n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> ExclamationBinaryFeatureExtractor:\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(lambda text: 0 + (self.char in text))\n",
    "        return feature.values.reshape(-1, 1)\n",
    "\n",
    "class CharCountFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts a text feature into a numeric feature count of the number of exclamation marks, which is\n",
    "    assumed to be yelling.\n",
    "    \"\"\"\n",
    "\n",
    "    char: str\n",
    "    \n",
    "    def __init__(self, char: str) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "    \n",
    "        if len(char) != 1:\n",
    "            raise ValueError('Character must be a string of length 1.')\n",
    "        \n",
    "        self.char = char\n",
    "\n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> ExclamationCountFeatureExtractor:\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(lambda text: text.count(self.char))\n",
    "        return feature.values.reshape(-1, 1)\n",
    "\n",
    "class SwearingFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Converts a text feature into a binary feature where 1 denotes swearing occurs, which is usually\n",
    "    seen in text as a series of 2 or more asterisks, e.g. ****.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "    \n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> SwearingFeatureExtractor:\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(lambda text: 0 + ('**' in text))\n",
    "        return feature.values.reshape(-1, 1)\n",
    "\n",
    "class RepeatedLetterFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        BaseEstimator.__init__(self)\n",
    "        TransformerMixin.__init__(self)\n",
    "\n",
    "    def __repeated_letter_binary(self, text: str) -> int:\n",
    "        return 1 if re.search(r'([a-zA-Z])\\1{2,}', text) else 0\n",
    "    \n",
    "    def fit(self, X: pd.Series, y: Optional[Any]=None) -> RepeatedLetterFeatureExtractor:\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: pd.Series) -> pd.DataFrame:\n",
    "        feature = X.apply(self.__repeated_letter_binary)\n",
    "        return feature.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295d9ef-c925-4bf8-af57-ef3f7cea91f4",
   "metadata": {},
   "source": [
    "## Reusable Funtionality to Evaluate a Model and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d85b4f7-d022-421a-b118-7cbdd7f0b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_save_results(pipeline: Pipeline, model_num: int) -> None:\n",
    "\n",
    "    X_val_prepared = X_val.copy()\n",
    "    X_test_prepared = X_test.copy()\n",
    "    X_val_prepared['Selected_Text'] = X_val['Text']\n",
    "    X_test_prepared['Selected_Text'] = X_test['Text']\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_val_pred = pipeline.predict(X_val_prepared)\n",
    "    y_test_pred = pipeline.predict(X_test_prepared)\n",
    "    \n",
    "    print(confusion_matrix(y_val, y_val_pred))\n",
    "    print(f'Precision: {precision_score(y_val, y_val_pred):.04f}')\n",
    "    print(f'Recall: {recall_score(y_val, y_val_pred):.04f}')\n",
    "    print(f'F1 Score: {f1_score(y_val, y_val_pred):.04f}')\n",
    "    \n",
    "    test_data_exportable = test_data.copy()\n",
    "    test_data_exportable['Label'] = y_test_pred\n",
    "    test_data_exportable = test_data_exportable[['ID', 'Label']]\n",
    "    test_data_exportable.to_csv(f'outputs/model{model_num}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547bc283-8639-440b-ab4e-775b1d98685e",
   "metadata": {},
   "source": [
    "## A \"Switchboard\" to Enable and Disable Running Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec2dc8f-f259-4423-bde7-49bbb10568ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_run = {\n",
    "    'model1': False,\n",
    "    'model2': False,\n",
    "    'model3': False,\n",
    "    'model4': False,\n",
    "    'model5': False,\n",
    "    'model6': False,\n",
    "    'model7': False,\n",
    "    'model8': False,\n",
    "    'model9': False,\n",
    "    'model10': False,\n",
    "    'model11': False,\n",
    "    'model12': False,\n",
    "    'model13': False,\n",
    "    'model14': False,\n",
    "    'model15': False,\n",
    "    'model16': False,\n",
    "    'model17': False,\n",
    "    'model18': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6f025-e9d6-44d4-91dd-719fd35a5599",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f71fec2b-ec70-4657-b292-ab6927e4917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model1']:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', LogisticRegression(random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26318e-fe4b-43e0-9f33-dc9197bf76e0",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a203be85-c41f-4b25-ab5e-0db3d651ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model2']:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', TfidfVectorizer(stop_words='english'), 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestClassifier(n_estimators=200, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb67b0d-8426-4782-a33d-8e3fd53ba086",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb3ac346-f71f-42a5-a04f-baf5558c84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model3']:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', CountVectorizer(stop_words='english'), 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestClassifier(n_estimators=200, random_state=1))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c956ec00-a5ad-4c84-a46d-fce808dc1f12",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2690bd90-a9a6-488b-8f4f-9d2d1d27662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model4']:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', CountVectorizer(stop_words='english'), 'Text'),\n",
    "            ('numeric', MinMaxScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', MultinomialNB()),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dd400e-8e0f-4924-bf52-c435f9d3a334",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "366b87e8-9c6c-4937-a5c8-20e615d1f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model5']:\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', CountVectorizer(stop_words='english'), 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', SVC(kernel='poly')),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e11bfd-094c-48eb-906f-a21502028c36",
   "metadata": {},
   "source": [
    "## Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2341d11b-4b3a-4982-abba-e62bfe4a040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model6']:        \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "        # ngram_range=(1, 2)\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('yelling', YellingBinaryFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestClassifier(n_estimators=200, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab6e8e-eb7d-4f7b-bf78-ee5b2a350693",
   "metadata": {},
   "source": [
    "## Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e94c9d4-bc0b-4145-bb23-c10bade5ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model7']:\n",
    "        \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "            ('exclamation', ExclamationCountFeatureExtractor(), 'Text'),\n",
    "            ('swearing', SwearingFeatureExtractor(), 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', LogisticRegression(random_state=1, max_iter=1000)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc77b1bf-8d1b-4351-b984-8d81aee2dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model8']:\n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "        # ngram_range=(1, 2)\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestClassifier(n_estimators=200, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e64f90b-c3b8-42b9-99fd-e9dfd873dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model9']:\n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestClassifier(n_estimators=225, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c00bfa-076b-4766-b298-9cccecb2f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model10']:\n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', RandomForestClassifier(n_estimators=225, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [220, 225, 230],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 10],\n",
    "        'min_samples_leaf': [1, 2],\n",
    "        'max_features': [None, 'sqrt', 'log2']\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=1), param_grid, cv=3, scoring='f1')\n",
    "    grid_search.fit(preprocessor.fit_transform(X_train_and_val), y_train_and_val)\n",
    "\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    # evaluate_and_save_results(pipeline, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc3cd1c-b862-487d-9364-226f635d0097",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model11']:\n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    voting_classifier = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('logistic_regression', LogisticRegression(random_state=1)),\n",
    "            ('random_forest', RandomForestClassifier(n_estimators=225, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('voting', voting_classifier),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "122f7b47-9fcd-4cbc-88a4-7be457360430",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model12']:    \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', ThresholdClassifier(RandomForestClassifier(n_estimators=225, random_state=1), 0.55)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c7505e-6a9a-4fd6-a31a-60ca563c279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model13']:\n",
    "    \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=221, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9128c4cc-2eb8-4a2b-840e-6fa93f686275",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model14']:\n",
    "    \n",
    "    text_chunk_vectorizer = CountVectorizer(\n",
    "        analyzer='char',\n",
    "        ngram_range=(3, 7),\n",
    "    )\n",
    "\n",
    "    text_word_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "\n",
    "    text_chunk_vectorization_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('cleaning', TextCleaner()),\n",
    "            ('vectorizing', text_chunk_vectorizer),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('chunks', text_chunk_vectorization_pipeline, 'Text'),\n",
    "            #('words', text_word_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "            #('swearing', SwearingFeatureExtractor(), 'Text'),\n",
    "            #('repeated_letters', RepeatedLetterFeatureExtractor(), 'Text')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            #('classification', RandomForestClassifier(n_estimators=221, random_state=1)),\n",
    "            ('classification', ThresholdClassifier(LogisticRegression(max_iter=1_000, random_state=1), 0.45)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a507ae67-2800-4cb0-becb-aedba076c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model15']:\n",
    "    \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            ('numeric', StandardScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('capitalization', CapsCountFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(n_estimators=221, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0621e31e-5ce8-4473-b4df-6e86d5640812",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model16']:\n",
    "    \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        #stop_words='english',\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', MinMaxScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            # ('capitalization', Pipeline([\n",
    "            #     ('extractor', CapsCountFeatureExtractor()),\n",
    "            #     ('scaler', MinMaxScaler()),\n",
    "            # ]), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', LogisticRegression(max_iter=1000, random_state=1)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2799b73-0827-410f-bc53-71072a632c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if models_to_run['model17']:\n",
    "    \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        #stop_words='english',\n",
    "        #ngram_range=(1, 2),\n",
    "        #max_features=10_000,\n",
    "        #min_df=11,\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', MinMaxScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            # ('capitalization', Pipeline([\n",
    "            #     ('extractor', CapsCountFeatureExtractor()),\n",
    "            #     ('scaler', MinMaxScaler()),\n",
    "            # ]), 'Text'),\n",
    "            #('exclamation', CharCountFeatureExtractor('!'), 'Text'),\n",
    "            #('question', CharCountFeatureExtractor('?'), 'Text'),\n",
    "            #('swearing', SwearingFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', ThresholdClassifier(LogisticRegression(max_iter=1000, random_state=1), 0.41)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f41db-7d01-470a-a0a8-ff65ff7fa6df",
   "metadata": {},
   "source": [
    "## Model 18 (My Best Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c3f18c0-cf85-4610-bb1f-93c0af5da872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2951  321]\n",
      " [ 385 1080]]\n",
      "Precision: 0.7709\n",
      "Recall: 0.7372\n",
      "F1 Score: 0.7537\n"
     ]
    }
   ],
   "source": [
    "if models_to_run['model18']:\n",
    "    \n",
    "    text_vectorizer = CountVectorizer(\n",
    "        #stop_words='english',\n",
    "        #ngram_range=(1, 2),\n",
    "        #max_features=10_000,\n",
    "        #min_df=11,\n",
    "    )\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numeric', MinMaxScaler(), ['User_Age', 'Time_of_Post', 'Population_Density']),\n",
    "            ('text', text_vectorizer, 'Text'),\n",
    "            # ('capitalization', Pipeline([\n",
    "            #     ('extractor', CapsCountFeatureExtractor()),\n",
    "            #     ('scaler', MinMaxScaler()),\n",
    "            # ]), 'Text'),\n",
    "            #('exclamation', CharCountFeatureExtractor('!'), 'Text'),\n",
    "            #('question', CharCountFeatureExtractor('?'), 'Text'),\n",
    "            #('swearing', SwearingFeatureExtractor(), 'Text'),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', ThresholdClassifier(LogisticRegression(max_iter=1000, random_state=1), 0.41)),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluate_and_save_results(pipeline, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd242da-1e1c-450f-af0d-45d8cf54167c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
